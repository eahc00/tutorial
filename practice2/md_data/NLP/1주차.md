  
자연어 처리가 뭐냐?
**자연어 : 가공되지 않은 언어** vs. 인공어(Artificial Language) : C, Python…  
- Format
    ex) Poem, letter, Book, ….
    → 단순히 문장만을 보는 게 아닌 맥락과 시간 등 모든 정보를 같이 봐야
    글을 이해하는 방식도 형식에 따라 달라진다.

  
- Age
    나이에 따라서도 쓰는 언어가 다르다.
    +) 어린 아이들(유아기)의 목소리가 가장 인식하기 힘들다.
    왜? 주파수가 다름.
    현재 음성인식 서비스는 데이터로 구축되는데 그 데이터 구축은 성인(?) 기준.
    

- 언어
    - Sender와 Receiver로 분류해서 볼 수 있다.
        **Sender ————NL Content————> Receiver**
        Sender와 Receiver가 같은 경우 : 일기
        1대 다수 : SNS
        

⇒ 언어가 단순히 글자들의 조합으로 끝나는 게 아니다. 문화, 경험, 지식 등의 공유해야 이해할 수 있다. : **같은 문화를 공유하지 않으면 언어는 이해할 수 없다.**
이러한 이해를 가지고 AI를 만들다면? → 문화를 이해시켜야
  
1. 어떻게 해야 언어처리를 잘 할 수 있을까?
2. 어떻게 지금의 인공지능들이 우리의 문화를 배울 수 있었을까?

---
컴퓨터를 이용한 자연어처리

### NLP History
  
자연어 → 언어학자들이 연구를 많이 해놓음.
ex) 촘스키(Chomsky)
  
**Rule-based NLP(규칙 기반 NLP) → statistical Model NLP(통계 기반 NLP) → Deep Learning NLP(2010)**

#### Rule-based NLP
- 어떤 큰 딕셔너리가 있다 → 딕셔너리를 룩업해서 다 분석한다. 
- 예를 들어 번역기를 만든다고 하면 "Hello는 안녕이야." 이런 식으로 하는 것


- **통계를 수를, 규칙은 기호를 다룬다.**
	ex) 규칙 기반 NLP에서 Cat = Cat (HARD)
	통계 기반 NLP에서 Cat은 수로 표현된다. (SOFT)
	고양이가 있다(1), 고양이가 없다(0) ⇒ HARD
	고양이일 확률(Float) = 0.8 ⇒ SOFT (분포를 따른다)
  
> [!problem]
> 규칙 기반에서는 기호가 없는 걸 표기할 수 없다. 기호화된 것만 표현할 수 있다.  
> 같은 걸 보더라도 기호가 달라지면 뜻이 완전히 달라진다.


통계 기반에서는 확률을 구해야.
  
- 확률을 구하는 두 가지 방법
	1. 귀납적 방법
	    ex) 주사위 100번 던져서 3이 몇번 나오나?
	    
	2. 연역적 방법
	    ex) 주사위 모양보고 연역적으로 추론
    
→ 따라서 **통계 기반 NLP에는 trial(데이터)이 필요**하다. == 이 방법은 DATA 기반의 NLP가 된다.
통계 기반으로 **파라미터(theta)를 추정.**


Deep Learning NLP
인공신경망 NLP.
**DNN으로 파라미터를 추정**
  
**Rule-based NLP(통계 기반 NLP) → statistical Model NLP(통계 기반 NLP) → Deep Learning NLP(2010) → Transformer based Fine-tuned NLP → Large Language Model based Zero-shot NLP(2022)**
  
_Transformer based fine-tuned NLP_
내가 모델을 Fine tuning 해야하는 방식
이후 트랜스포머 NLP → 2022년에 chatGPT
  
_Large Language Model based Zero-shot NLP_
**좋은 질문(prompt)을 던지는 방식**. 내가 학습 시키는 게 아니다.


NLP Datasets(GLUE, super-GLUE… 등 benchmark dst)을 가지고 여러 task를 위 두 가지 방식으로 구현해볼 것.
---
  
학습 목표(기대)
1. NLP의 주요한 개념에 대해 설명할 수 있다.
2. NLP task implement 가능.
    → transformer, Large Model 두 가지 방법.


###### 도메인 한정 생성 모델 Domain constrainted Generate Language model