{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `naver_changwon_ner` is already installed at /home/eahc00/Korpora/naver_changwon_ner/train_data\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.fetch('naver_changwon_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : 네이버 + 창원대\n",
      "    Repository : https://github.com/naver/nlp-challenge/tree/master/missions/ner\n",
      "    References : http://air.changwon.ac.kr/?page_id=10\n",
      "\n",
      "    개체명(Named Entity)은 인명, 기관명, 지명 등과 같이 문장 또는 문서에서 특정한 의미를 가지고 있는 단어 또는 어구를 말합니다.\n",
      "    이 때문에 개체명은 정보 검색 및 언어 이해를 위한 분석에서 주요한 대상으로 다루어지고 있습니다.\n",
      "    Data.ly에서는 개체명 코퍼스를 제공하여 연구에 도움을 드리고자 하며, 공개적인 리더보드를 통해 많은 분들의 연구 동향을 논의/공유하고자 합니다.\n",
      "    제공되는 코퍼스는 Data.ly에서 제작한 것으로, 연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
      "\n",
      "    # License\n",
      "    연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
      "\n",
      "[Korpora] Corpus `naver_changwon_ner` is already installed at /home/eahc00/tutorial/korean_ner/Korpora/naver_changwon_ner/train_data\n"
     ]
    }
   ],
   "source": [
    "corpus = Korpora.load('naver_changwon_ner', root_dir='/home/eahc00/tutorial/korean_ner/Korpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordTag(text='이 음경동맥의 직경이 8 19mm입니다 . ', words=['이', '음경동맥의', '직경이', '8', '19mm입니다', '.'], tags=['-', '-', '-', 'NUM_B', 'NUM_B', '-'])\n",
      "90000\n",
      "이 음경동맥의 직경이 8 19mm입니다 . \n",
      "['-', '-', '-', 'NUM_B', 'NUM_B', '-']\n",
      "['이', '음경동맥의', '직경이', '8', '19mm입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(corpus.train[idx])\n",
    "\n",
    "print(len(corpus.train))\n",
    "\n",
    "print(corpus.get_all_texts()[idx])\n",
    "print(corpus.get_all_tags()[idx])\n",
    "print(corpus.get_all_words()[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비토리오 양일 만에 영사관 감호 용퇴, 항룡 압력설 의심만 가율 \n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[비토리오:PER] [양일:DAT] 만에 [영사관:ORG] [감호:CVL] 용퇴, 항룡 압력설 의심만 가율\n",
      "이 음경동맥의 직경이 [8:NUM] [19mm입니다:NUM] .\n",
      "[9세이브로:NUM] 구완 [30위인:NUM] [LG:ORG] [박찬형은:PER] 평균자책점이 [16.45로:NUM] 준수한 편이지만 [22⅓이닝:NUM] 동안 피홈런이 [31개나:NUM] 된다 .\n",
      "[7승:NUM] [25패는:NUM] [상트페테르부르크가:LOC] 역대 [월드리그에:EVT] 출진한 분별 최선의 성적이다 .\n",
      "▲ [퍼거슨:PER] [씨족의:CVL] 꾀\n",
      "[[유로2008]:EVT] ['공인구가:CVL] 변할 기록 [시정조치는:CVL] 죽을 맛 ? '\n",
      "[로마올림픽에서:EVT] [육미지황탕:TRM] [이남지역으로:TRM] [동메달에:CVL] 머문 [추경대는:PER] [차년:DAT] [파리오픈:EVT] [결승전에서:EVT] 진 [동영의:LOC] [탄셰:PER] [차우세스쿠를:PER] 비롯해 [몽골의:LOC] [이창동:PER] [차간바,:PER] [발보나의:LOC] [리자루드:PER] [박혜미셔:PER] [좌타자를:CVL] 놓고 추축한다 .\n",
      "금반 [명기:CVL] [통합우승:CVL] [24,:NUM] [10회차는:NUM] [8일:DAT] [상오:TIM] [6시:TIM] [50분,:TIM] [상오:TIM] [11시:TIM] [50분에:TIM] 발태가 끝마감되며, 비공식 적중결과는 [5일:DAT] 공표된다 .\n",
      "권뢰가 있는 곳에 직경에 따라 달라지는데요 .\n",
      "때로는은 귀여운 가스나기인 비담, 세상일에는 무관심 .\n",
      "[22회말:NUM] [21-21:NUM] 동점타의 [꼬냑인:CVL] [LG:ORG] [막둥이:CVL] [이종열은:PER] \"팀이 어려울 때 귀중한 타점을 올려 원기가 좋다 .\n",
      "▶ [케빈:PER] [가넷,:PER] [보스턴행:LOC] ['확정'…올스타:CVL] [19인방:NUM] '기대만발'\n",
      "[옥구권에서:LOC] [2홀:NUM] 돌 소요액이면 [제주에서:LOC] [23홀도:NUM] 가능하다는 얘기다 .\n",
      "트레이드 규정은 격력적이다 .\n",
      "[서형곤:PER] [대통령은:CVL] [박재천:PER] [지신과의:CVL] [브뤼셀:LOC] · [필리핀:LOC] 정상회담을 통해 양국 간 실질협력 증진방안에 대해 관점을 교역하고 [△IT:TRM] 직업훈련원 개소식 결근 △양국 민간경제협의회 웅변 [△필리핀:LOC] [동대정자마을:LOC] 참전용사 대표자 접면 등의 일정을 소화할 계획이다 .\n",
      "[삼천리강산:LOC] 내 최저 [MP3플레이어:TRM] 전문업체, 천지간 마켓에서 혹평받는 [MP3플레이어라는:TRM] 성공담은 버렸다 .\n",
      "무선데이터통신 및 무선호출사업자들이 기존 장비를 변통해 ‘교통정보 이바지 사업자’로 옷을 갈아입을 태세다 .\n",
      "[이상주기자:PER] [divayuni@-:TRM] 주소창에 '스포츠'만 치시면 [유디치과그룹:ORG] 기졸이 [한눈에:ANM] !\n",
      "개개인적으로 노심을 해야 할 것 같다 .\n",
      "◇전술이 된 거친 항변 [브리티시여자오픈:EVT] [챔프전도:EVT] 극렬한 항변이 연속됐다 .\n"
     ]
    }
   ],
   "source": [
    "from tutorial.korean_ner.utils import results_out\n",
    "\n",
    "for i in range(0, 20):\n",
    "    print(results_out(corpus.train[i].words, corpus.train[i].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordTag(text='9세이브로 구완 30위인 LG 박찬형은 평균자책점이 16.45로 준수한 편이지만 22⅓이닝 동안 피홈런이 31개나 된다 . ', words=['9세이브로', '구완', '30위인', 'LG', '박찬형은', '평균자책점이', '16.45로', '준수한', '편이지만', '22⅓이닝', '동안', '피홈런이', '31개나', '된다', '.'], tags=['NUM_B', '-', 'NUM_B', 'ORG_B', 'PER_B', '-', 'NUM_B', '-', '-', 'NUM_B', '-', '-', 'NUM_B', '-', '-'])\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaverChangwonNER.train: size=90000\n",
       "  - NaverChangwonNER.train.texts : list[str]\n",
       "  - NaverChangwonNER.train.words : list[list]\n",
       "  - NaverChangwonNER.train.tags : list[list]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = corpus.get_all_tags()\n",
    "\n",
    "tag_set = set()\n",
    "\n",
    "for tag in tags:\n",
    "    tag = set(tag)\n",
    "    tag_set.update(tag)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "['-', 'AFW_B', 'AFW_I', 'ANM_B', 'ANM_I', 'CVL_B', 'CVL_I', 'DAT_B', 'DAT_I', 'EVT_B', 'EVT_I', 'FLD_B', 'FLD_I', 'LOC_B', 'LOC_I', 'MAT_B', 'MAT_I', 'NUM_B', 'NUM_I', 'ORG_B', 'ORG_I', 'PER_B', 'PER_I', 'PLT_B', 'PLT_I', 'TIM_B', 'TIM_I', 'TRM_B', 'TRM_I']\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_set))\n",
    "print(sorted(list(tag_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331196\n"
     ]
    }
   ],
   "source": [
    "words = corpus.get_all_words()\n",
    "\n",
    "word_set = set()\n",
    "\n",
    "for word in words:\n",
    "    word = set(word)\n",
    "    word_set.update(word)\n",
    "\n",
    "print(len(word_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eahc00/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_model\n",
    "from tutorial.korean_ner.model import Model\n",
    "from tutorial.commons import BERT_CONFIG\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "hg_config = BertConfig.from_pretrained(model_name)\n",
    "num_lables = 29\n",
    "\n",
    "my_config = BERT_CONFIG(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    padding_idx=tokenizer.convert_tokens_to_ids(\"[PAD]\"),\n",
    "    max_seq_length=hg_config.max_position_embeddings,\n",
    "    d_model=hg_config.hidden_size,\n",
    "    layer_norm_eps=hg_config.layer_norm_eps,\n",
    "    emb_hidden_dropout=hg_config.hidden_dropout_prob,\n",
    "    num_layers=hg_config.num_hidden_layers,\n",
    "    num_heads=hg_config.num_attention_heads,\n",
    "    att_prob_dropout=hg_config.attention_probs_dropout_prob,\n",
    "    dim_feedforward=hg_config.intermediate_size,\n",
    "    pooled_output=False,\n",
    ")\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    bert_config=my_config,\n",
    "    num_labels=num_lables,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['비', '##토', '##리', '##오'], 'PER_B')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenizer.tokenize(corpus.train[0].words[0])\n",
    "b = corpus.train[0].tags[0]\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : 네이버 + 창원대\n",
      "    Repository : https://github.com/naver/nlp-challenge/tree/master/missions/ner\n",
      "    References : http://air.changwon.ac.kr/?page_id=10\n",
      "\n",
      "    개체명(Named Entity)은 인명, 기관명, 지명 등과 같이 문장 또는 문서에서 특정한 의미를 가지고 있는 단어 또는 어구를 말합니다.\n",
      "    이 때문에 개체명은 정보 검색 및 언어 이해를 위한 분석에서 주요한 대상으로 다루어지고 있습니다.\n",
      "    Data.ly에서는 개체명 코퍼스를 제공하여 연구에 도움을 드리고자 하며, 공개적인 리더보드를 통해 많은 분들의 연구 동향을 논의/공유하고자 합니다.\n",
      "    제공되는 코퍼스는 Data.ly에서 제작한 것으로, 연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
      "\n",
      "    # License\n",
      "    연구 및 리더보드를 위한 학습으로 사용 가능하며 상업적인 목적으로 사용될 수 없습니다.\n",
      "\n",
      "[Korpora] Corpus `naver_changwon_ner` is already installed at /home/eahc00/tutorial/korean_ner/Korpora/naver_changwon_ner/train_data\n",
      "Words: ['관세청은', '울산', '경남', '경북지역', '등에', '대규모', '산불이', '발생함에', '따라', '신속한', '복구와', '피해기업', '지원을', '위한', '관세행정', '종합지원방안을', '수립해', '추진한다고', '26일', '밝혔다.']\n",
      "Predicted NER tags: ['ORG_B', 'LOC_B', 'LOC_B', 'LOC_B', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'DAT_B', '-']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "from tutorial.korean_ner.dataset import NERDataModule\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# 1. 모델과 토크나이저 불러오기\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "load_model(model, \"../ner_model.safetensors\")\n",
    "dataloader = NERDataModule(tokenizer, None, None)\n",
    "\n",
    "# 2. 입력 문장 전처리\n",
    "input_sentence = \"관세청은 울산 경남 경북지역 등에 대규모 산불이 발생함에 따라 신속한 복구와 피해기업 지원을 위한 관세행정 종합지원방안을 수립해 추진한다고 26일 밝혔다.\"\n",
    "words = input_sentence.split()\n",
    "\n",
    "encoded = tokenizer(\n",
    "    words,\n",
    "    is_split_into_words=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "input_ids = encoded.input_ids\n",
    "attention_mask = encoded.attention_mask\n",
    "\n",
    "# 3. 모델 추론\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    logits = outputs[\"logits\"]\n",
    "\n",
    "# 4. 토큰별 예측 결과\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# 5. 원래 단어 단위로 매핑\n",
    "word_ids = encoded.word_ids(batch_index=0)\n",
    "pred_labels = predictions[0].tolist()\n",
    "\n",
    "word_predictions = []\n",
    "previous_word_idx = None\n",
    "for idx, word_idx in enumerate(word_ids):\n",
    "    if word_idx is None:\n",
    "        continue\n",
    "    if word_idx != previous_word_idx:\n",
    "        word_predictions.append(pred_labels[idx])\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "# 6. 인덱스를 실제 태그로 변환 (학습 시 사용한 label2idx에 맞춰서 수정)\n",
    "idx2label = {idx: label for label, idx in dataloader.label2idx.items()}\n",
    "predicted_tags = [idx2label[label_idx] for label_idx in word_predictions]\n",
    "\n",
    "print(\"Words:\", words)\n",
    "print(\"Predicted NER tags:\", predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_out(words, predicted_tags):\n",
    "    tagged_words = []\n",
    "    for word, predicted_tag in zip(words, predicted_tags):\n",
    "        if predicted_tag != \"-\":\n",
    "            tagged_word = f\"[{word}:{predicted_tag.split('_')[0]}]\"\n",
    "            tagged_words.append(tagged_word)\n",
    "        else:\n",
    "            tagged_words.append(word)\n",
    "\n",
    "    return \" \".join(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[관세청은:ORG] [울산:LOC] [경남:LOC] [경북지역:LOC] 등에 대규모 산불이 발생함에 따라 신속한 복구와 피해기업 지원을 위한 관세행정 종합지원방안을 수립해 추진한다고 [26일:DAT] 밝혔다.\n"
     ]
    }
   ],
   "source": [
    "print(results_out(words, predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>”라고 머쓱해했을 한도로 여유로운( ? ) 연습 일정을 소화했다 .</td>\n",
       "      <td>”라고 머쓱해했을 한도로 여유로운( ? ) 연습 일정을 소화했다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“KAIST를 입학한 뒤 7년 ‘디어사이드3’이라고하는 열수력종합효과실험장치 PC게...</td>\n",
       "      <td>[“KAIST를:ORG] 입학한 뒤 [7년:DAT] [‘디어사이드3’이라고하는:OR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어떤 안무에도 맞는 신기한 음률 지원자 오오오오 .</td>\n",
       "      <td>어떤 안무에도 맞는 신기한 음률 [지원자:CVL] [오오오오:PER] .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- 주소창에 '스포츠'만 치시면 스펙트럼 나이트가 한눈에 !</td>\n",
       "      <td>- 주소창에 '스포츠'만 치시면 [스펙트럼:ORG] 나이트가 [한눈에:ANM] !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>좋은 종류를 얻기 위해서 9년에 28만개 최선의 꽃을 교배해야 한다 .</td>\n",
       "      <td>좋은 종류를 얻기 위해서 [9년에:DAT] [28만개:NUM] 최선의 [꽃을:PLT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0              ”라고 머쓱해했을 한도로 여유로운( ? ) 연습 일정을 소화했다 .   \n",
       "1  “KAIST를 입학한 뒤 7년 ‘디어사이드3’이라고하는 열수력종합효과실험장치 PC게...   \n",
       "2                       어떤 안무에도 맞는 신기한 음률 지원자 오오오오 .   \n",
       "3                  - 주소창에 '스포츠'만 치시면 스펙트럼 나이트가 한눈에 !   \n",
       "4            좋은 종류를 얻기 위해서 9년에 28만개 최선의 꽃을 교배해야 한다 .   \n",
       "\n",
       "                                           reference  \n",
       "0              ”라고 머쓱해했을 한도로 여유로운( ? ) 연습 일정을 소화했다 .  \n",
       "1  [“KAIST를:ORG] 입학한 뒤 [7년:DAT] [‘디어사이드3’이라고하는:OR...  \n",
       "2           어떤 안무에도 맞는 신기한 음률 [지원자:CVL] [오오오오:PER] .  \n",
       "3      - 주소창에 '스포츠'만 치시면 [스펙트럼:ORG] 나이트가 [한눈에:ANM] !  \n",
       "4  좋은 종류를 얻기 위해서 [9년에:DAT] [28만개:NUM] 최선의 [꽃을:PLT...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_base = pd.read_csv(\"../test_base.csv\")\n",
    "test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial.korean_ner.ner_bert_inference import NERBERTInference\n",
    "from tutorial.korean_ner.utils import results_out\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "num_labels = 29\n",
    "\n",
    "ner_bert_inference = NERBERTInference(model_name, num_labels)\n",
    "predicted_sentence = []\n",
    "data_rows = []\n",
    "\n",
    "for sentence in test_base[\"sentence\"]:\n",
    "    words, tags = ner_bert_inference.ner_inference(sentence)\n",
    "    predicted_sentence.append(results_out(words, tags))\n",
    "    data_rows.append({\"words\": words, \"tags\": tags})\n",
    "\n",
    "test_pred_words_and_tags = pd.DataFrame(data_rows)\n",
    "# test_pred_words_and_tags.to_csv(\"pred_test_words_and_tags.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base[\"prediction\"] = predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base.to_csv(\"./test_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def read_csv_to_df(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df[\"words\"] = df[\"words\"].apply(ast.literal_eval)\n",
    "    df[\"tags\"] = df[\"tags\"].apply(ast.literal_eval)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag: str) -> str:\n",
    "    \"\"\"\n",
    "    예: 'DAT_B' -> 'B-DAT'\n",
    "       'NUM_I' -> 'I-NUM'\n",
    "       '-'     -> 'O'\n",
    "    \"\"\"\n",
    "    if tag == '-':\n",
    "        return 'O'\n",
    "    # 만약 TAG_PREFIX_LABEL 형식이라면\n",
    "    # 예: DAT_B,  NUM_I\n",
    "    # 스플릿 후 뒤 쪽이 B or I인지 확인\n",
    "    try:\n",
    "        label, prefix = tag.split('_')\n",
    "        # prefix가 'B'면 'B-LABEL', 'I'면 'I-LABEL'\n",
    "        return f\"{prefix}-{label}\"\n",
    "    except:\n",
    "        # 혹시 예외가 있으면 일단 O\n",
    "        return 'O'\n",
    "\n",
    "example_seq = ['DAT_B', '-', 'NUM_I', '-']\n",
    "converted_seq = [convert_tag(t) for t in example_seq]\n",
    "print(converted_seq)\n",
    "# ['B-DAT', 'O', 'I-NUM', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from tutorial.korean_ner.utils import tags\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "f1 = [] \n",
    "\n",
    "ref_df = read_csv_to_df(\"../test_words_and_tags.csv\")\n",
    "pred_df = read_csv_to_df(\"./pred_test_words_and_tags.csv\")\n",
    "\n",
    "for ref, pred in zip(ref_df[\"tags\"], pred_df[\"tags\"]):\n",
    "    converted_ref = [convert_tag(t) for t in ref]\n",
    "    converted_pred = [convert_tag(t) for t in pred]\n",
    "    \n",
    "    result = seqeval.compute(\n",
    "        predictions=[converted_pred], \n",
    "        references=[converted_ref], \n",
    "        # labesl=tags,\n",
    "        zero_division=0,\n",
    "        # average='macro'\n",
    "    )\n",
    "    # print(result[\"overall_f1\"])\n",
    "    f1.append(result['overall_f1'])\n",
    "\n",
    "test_base[\"f1\"] = f1\n",
    "test_base.to_csv(\"./result_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base[1:6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
